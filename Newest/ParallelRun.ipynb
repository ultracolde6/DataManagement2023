{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider how a parallel running scheme ought to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may be fun to have things be read in from txt file with params\n",
    "from importlib import reload\n",
    "import os\n",
    "import GagePreprocess as gp\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import time\n",
    "\n",
    "reload(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_impl(save_path, jkam_path, gage_path):\n",
    "    # TODO: nothing fancy, just keep stacking more and more pickl files after waiting 15 seconds\n",
    "    curr_files = []\n",
    "    new_files = []\n",
    "    curr_cmplx_path = ''\n",
    "    curr_time_path = ''\n",
    "    first_step = True\n",
    "    curr_time_pkl = ''\n",
    "    curr_cmplx_pkl = ''\n",
    "    former_time_pkl = ''\n",
    "    former_cmplx_pkl = ''\n",
    "    curr_cmplx_arr = []\n",
    "    curr_time_arr = []\n",
    "    # TODO: there's something weird going on with how things are indexed in jkam\n",
    "    # TODO: bug: if jkam gets files before gage, there will be a bug in the file mask\n",
    "    # gage will basically try and index up to jkam file number and will go out of range\n",
    "    curr_length = len(os.listdir(gage_path))\n",
    "    first_run = True\n",
    "    while True:\n",
    "        print(\"Current length of gage path: \", curr_length)\n",
    "        new_length = len(os.listdir(gage_path))\n",
    "        if first_run or new_length > curr_length:\n",
    "            # need try except since mismatch between jkam files and gage files will break the thing\n",
    "            try:\n",
    "                cmplx_path, time_path, cmplx_amp, time_amp = gp.process_gage_pkl(save_path, \n",
    "                                                                                'run0', \n",
    "                                                                                286,\n",
    "                                                                                3, \n",
    "                                                                                'high NA Imaging testenv', \n",
    "                                                                                'gage testenv')\n",
    "                print(\"files processed again. current file number is : \", new_length)\n",
    "                time.sleep(2)\n",
    "                first_run = False\n",
    "                curr_length = new_length\n",
    "            except Exception as e:\n",
    "                print(\"processing failed. The following error occurred: \", e)\n",
    "            time.sleep(4)\n",
    "        else:\n",
    "            print(\"No new files to process.\")\n",
    "            time.sleep(4)\n",
    "            continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_impl('TestPkl', 'High NA Imaging testenv', 'gage testenv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given two pkl file paths, combine them into a single pkl file\n",
    "def pkl_combiner(pkl1, pkl2):\n",
    "    # load the pkl files, data are arrays\n",
    "    data1 = gp.load_pkl(pkl1)\n",
    "    data2 = gp.load_pkl(pkl2)\n",
    "    # combine the data\n",
    "    data = np.concatenate((data1, data2), axis=0)\n",
    "    # repickle the data\n",
    "    with open(pkl2, 'wb') as f:\n",
    "        pkl.dump(data, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pkl_deleter(pkl_files, dir_path):\n",
    "    if len(pkl_files) >= 3:\n",
    "        # delete the one with the earliest creation time\n",
    "        ctimes = [os.path.getctime(os.path.join(dir_path, name)) for name in pkl_files]\n",
    "        min_ctime_idx = ctimes.index(min(ctimes))\n",
    "        os.remove(os.path.join(dir_path, pkl_files[min_ctime_idx]))\n",
    "        print(\"Old pkl file removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gage_match_check(file_list, file_number, increment_number):\n",
    "    # for example if we are at file 50 with increment 5, we should expect to see the files 44, 45, 46, 47, 48, 49\n",
    "    correct_suffix = file_number - increment_number - 1\n",
    "    correct_files = [f for f in file_list if str(correct_suffix) in f.split('_')[-1].lstrip('0')]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_process(save_path, file_incr, jkam_path = 'High NA Imaging testenv', gage_path = 'gage testenv'):\n",
    "    curr_files = []\n",
    "    new_files = []\n",
    "    curr_cmplx_path = ''\n",
    "    curr_time_path = ''\n",
    "    first_step = True\n",
    "    file_num = file_incr\n",
    "    curr_time_pkl = ''\n",
    "    curr_cmplx_pkl = ''\n",
    "    former_time_pkl = ''\n",
    "    former_cmplx_pkl = ''\n",
    "    curr_cmplx_arr = []\n",
    "    curr_time_arr = []\n",
    "\n",
    "    # get num files in folder\n",
    "    total_files = len([name for name in os.listdir(gage_path) if os.path.isfile(os.path.join(gage_path, name))])\n",
    "    if total_files >= file_num and first_step:\n",
    "        print(\"first step \\n\")\n",
    "        # store all file names\n",
    "        curr_files = [name for name in os.listdir(gage_path) if os.path.isfile(os.path.join(gage_path, name))]\n",
    "        # files tend to get read in out of order and need to be ordered\n",
    "        new_files = curr_files\n",
    "        print(curr_files)\n",
    "        print(new_files)\n",
    "        # TODO: need edge cases to check that gage number match amount of files added, just in case there are extras and the sequence gets messed up\n",
    "        # run preprocessor on new files\n",
    "\n",
    "        # TODO: need to send new files into gage preprocessing instead of just a path\n",
    "        # TODO: all additional checks need to be done on the segmented files...\n",
    "        curr_amp_path, curr_time_path, curr_amp, curr_time = gp.process_gage_pkl(out_path = save_path, \n",
    "                                                                run_name = 'run0', \n",
    "                                                                num_shots_manual = 286,\n",
    "                                                                num_frames = 3,\n",
    "                                                                jkam_path = jkam_path,\n",
    "                                                                gage_path = gage_path,\n",
    "                                                                jkam_prefix = 'jkam_capture',\n",
    "                                                                gage_prefix = 'gage_shot')\n",
    "        # we also need to output filepath of pkl files\n",
    "        first_step = False\n",
    "        file_num += file_incr\n",
    "\n",
    "    elif total_files >= file_num:\n",
    "        print(\"enough files incremented, executing again... \\n\")\n",
    "        curr_files = [name for name in os.listdir(gage_path) if os.path.isfile(os.path.join(gage_path, name))]\n",
    "        new_files = [x for x in curr_files if x not in new_files]\n",
    "        former_time_pkl = curr_time_pkl\n",
    "        former_cmplx_pkl = curr_cmplx_pkl   \n",
    "        # run preprocessor on new files\n",
    "        curr_amp_path, curr_time_path, curr_amp, curr_time = gp.process_gage_pkl(out_path = save_path, \n",
    "                                                                run_name = 'run0', \n",
    "                                                                num_shots_manual = 286,\n",
    "                                                                num_frames = 3,\n",
    "                                                                jkam_path = jkam_path,\n",
    "                                                                gage_path = gage_path,\n",
    "                                                                jkam_prefix = 'jkam_capture',\n",
    "                                                                gage_prefix = 'gage_shot')\n",
    "        # combine new and old pkl files\n",
    "        pkl_combiner(former_time_pkl, curr_time_path)\n",
    "        pkl_combiner(former_cmplx_pkl, curr_amp_path)\n",
    "\n",
    "        dir_path = os.path.dirname(former_time_pkl)\n",
    "        # get if there are three files that are .pkl in this directory\n",
    "        amp_pkl_files = [name for name in os.listdir(dir_path) \n",
    "                    if os.path.isfile(os.path.join(dir_path, name)) and name.endswith('.pkl') and 'cmplx_amp' in name]\n",
    "        time_pkl_files = [name for name in os.listdir(dir_path) \n",
    "                    if os.path.isfile(os.path.join(dir_path, name)) and name.endswith('.pkl') and 'time' in name]\n",
    "        \n",
    "        pkl_deleter(amp_pkl_files, dir_path)\n",
    "        pkl_deleter(time_pkl_files, dir_path)\n",
    "\n",
    "    else:\n",
    "        print(\"not enough files, waiting... \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_process(save_path = 'High NA Imaging testenv', file_incr=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_incr):\n",
    "    while True:\n",
    "        time.sleep(2)\n",
    "        cycle_process('out', file_incr)\n",
    "        print(\"cycled once\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
